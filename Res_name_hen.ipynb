{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986c15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cc0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = []\n",
    "noun = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3922c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latin American\n",
    "latin_adjectives = ['spicy', 'flavorful', 'zesty', 'tangy']\n",
    "latin_nouns = ['salsa', 'taco', 'empanada', 'chorizo']\n",
    "\n",
    "adj.append(latin_adjectives)\n",
    "noun.append(latin_nouns)\n",
    "# Burgers\n",
    "burger_adjectives = ['juicy', 'grilled', 'savory', 'gourmet']\n",
    "burger_nouns = ['patty', 'bun', 'cheese', 'bacon']\n",
    "\n",
    "adj.append(burger_adjectives)\n",
    "noun.append(burger_nouns)\n",
    "# African\n",
    "african_adjectives = ['exotic', 'earthy', 'rich', 'fragrant']\n",
    "african_nouns = ['stew', 'jollof', 'plantain', 'fufu']\n",
    "\n",
    "adj.append(african_adjectives)\n",
    "noun.append(african_nouns)\n",
    "# Turkish\n",
    "turkish_adjectives = ['spiced', 'sizzling', 'smoky', 'satisfying']\n",
    "turkish_nouns = ['kebab', 'pide', 'borek', 'baklava']\n",
    "\n",
    "adj.append(turkish_adjectives)\n",
    "noun.append(turkish_nouns)\n",
    "# Bakery\n",
    "bakery_adjectives = ['fresh', 'crusty', 'buttery', 'sweet']\n",
    "bakery_nouns = ['croissant', 'baguette', 'pastry', 'donut']\n",
    "adj.append(bakery_adjectives)\n",
    "noun.append(bakery_nouns)\n",
    "# Sandwiches\n",
    "sandwich_adjectives = ['toasted', 'hearty', 'loaded', 'grilled']\n",
    "sandwich_nouns = ['sub', 'club', 'panini', 'grinder']\n",
    "adj.append(sandwich_adjectives)\n",
    "noun.append(sandwich_nouns)\n",
    "# Italian\n",
    "italian_adjectives = ['authentic', 'homemade', 'cheesy', 'hearty']\n",
    "italian_nouns = ['pasta', 'pizza', 'lasagna', 'risotto']\n",
    "adj.append(italian_adjectives)\n",
    "noun.append(italian_nouns)\n",
    "\n",
    "# Fast-Food\n",
    "fast_food_adjectives = ['quick', 'convenient', 'greasy', 'cheap']\n",
    "fast_food_nouns = ['burger', 'fries', 'nuggets', 'hotdog']\n",
    "adj.append(fast_food_adjectives)\n",
    "noun.append(fast_food_nouns)\n",
    "# Chinese\n",
    "chinese_adjectives = ['savory', 'umami', 'crispy', 'flavorful']\n",
    "chinese_nouns = ['dumpling', 'noodle', 'bao', 'fried rice']\n",
    "adj.append(chinese_adjectives)\n",
    "noun.append(chinese_nouns)\n",
    "# Vegetarian\n",
    "vegetarian_adjectives = ['wholesome', 'fresh', 'colorful', 'nutritious']\n",
    "vegetarian_nouns = ['salad', 'wrap', 'bowl', 'quinoa']\n",
    "adj.append(vegetarian_adjectives)\n",
    "noun.append(vegetarian_nouns)\n",
    "# Coffee\n",
    "coffee_adjectives = ['bold', 'aromatic', 'smooth', 'rich']\n",
    "coffee_nouns = ['espresso', 'latte', 'cappuccino', 'mocha']\n",
    "adj.append(coffee_adjectives)\n",
    "noun.append(coffee_nouns)\n",
    "# Contemporary\n",
    "contemporary_adjectives = ['innovative', 'creative', 'unique', 'eclectic']\n",
    "contemporary_nouns = ['fusion', 'tapas', 'small plates', 'shared plates']\n",
    "adj.append(contemporary_adjectives)\n",
    "noun.append(contemporary_nouns)\n",
    "# Dutch\n",
    "dutch_adjectives = ['traditional', 'hearty', 'wholesome', 'satisfying']\n",
    "dutch_nouns = ['stamppot', 'poffertjes', 'herring', 'kroket']\n",
    "adj.append(dutch_adjectives)\n",
    "noun.append(dutch_nouns)\n",
    "# Ice-Cream\n",
    "ice_cream_adjectives = ['creamy', 'indulgent', 'decadent', 'refreshing']\n",
    "ice_cream_nouns = ['cone', 'sundae', 'gelato', 'milkshake']\n",
    "adj.append(ice_cream_adjectives)\n",
    "noun.append(ice_cream_nouns)\n",
    "# Mexican\n",
    "mexican_adjectives = ['fiery', 'zesty', 'colorful', 'bold']\n",
    "mexican_nouns = ['enchilada', 'quesadilla', 'burrito', 'guacamole']\n",
    "adj.append(mexican_adjectives)\n",
    "noun.append(mexican_nouns)\n",
    "# Greek\n",
    "greek_adjectives = ['fresh', 'crispy', 'tangy', 'savory']\n",
    "greek_nouns = ['gyro', 'souvlaki', 'tzatziki', 'spanakopita']\n",
    "adj.append(greek_adjectives)\n",
    "noun.append(greek_nouns)\n",
    "# Japanese\n",
    "japanese_adj = [\"sushi\", \"tempura\", \"umami\", \"teriyaki\"]\n",
    "japanese_noun = [\"ramen\", \"soba\", \"udon\", \"izakaya\"]\n",
    "adj.append(japanese_adj)\n",
    "noun.append(japanese_noun)\n",
    "# Pizzeria\n",
    "pizzeria_adj = [\"wood-fired\", \"authentic\", \"gourmet\", \"crispy\"]\n",
    "pizzeria_noun = [\"pizza\", \"calzone\", \"stromboli\", \"focaccia\"]\n",
    "adj.append(pizzeria_adj)\n",
    "noun.append(pizzeria_noun)\n",
    "# Steaks\n",
    "steaks_adj = [\"juicy\", \"tender\", \"flavorful\", \"prime\"]\n",
    "steaks_noun = [\"ribeye\", \"filet mignon\", \"strip steak\", \"porterhouse\"]\n",
    "adj.append(steaks_adj)\n",
    "noun.append(steaks_noun)\n",
    "# Asian\n",
    "asian_adj = [\"spicy\", \"aromatic\", \"savory\", \"umami\"]\n",
    "asian_noun = [\"stir-fry\", \"dumplings\", \"pho\", \"curry\"]\n",
    "adj.append(asian_adj)\n",
    "noun.append(asian_noun)\n",
    "# Seafood\n",
    "seafood_adj = [\"fresh\", \"succulent\", \"flaky\", \"buttery\"]\n",
    "seafood_noun = [\"lobster\", \"oysters\", \"clams\", \"crab\"]\n",
    "adj.append(seafood_adj)\n",
    "noun.append(seafood_noun)\n",
    "# Bar\n",
    "bar_adj = [\"craft\", \"bespoke\", \"innovative\", \"locally-sourced\"]\n",
    "bar_noun = [\"cocktails\", \"beer\", \"whiskey\", \"wine\"]\n",
    "adj.append(bar_adj)\n",
    "noun.append(bar_noun)\n",
    "# French\n",
    "french_adj = [\"buttery\", \"rich\", \"decadent\", \"elegant\"]\n",
    "french_noun = [\"croissant\", \"brioche\", \"escargot\", \"ratatouille\"]\n",
    "adj.append(french_adj)\n",
    "noun.append(french_noun)\n",
    "# International\n",
    "international_adj = [\"fusion\", \"global\", \"eclectic\", \"diverse\"]\n",
    "international_noun = [\"tapas\", \"sushi\", \"pasta\", \"curry\"]\n",
    "adj.append(international_adj)\n",
    "noun.append(international_noun)\n",
    "# Bar Pub Brewery\n",
    "bar_pub_brewery_adj = [\"hoppy\", \"refreshing\", \"frothy\", \"malty\"]\n",
    "bar_pub_brewery_noun = [\"beer\", \"ale\", \"stout\", \"porter\"]\n",
    "adj.append(bar_pub_brewery_adj)\n",
    "noun.append(bar_pub_brewery_noun)\n",
    "# Korean\n",
    "korean_adj = [\"spicy\", \"fermented\", \"savory\", \"crispy\"]\n",
    "korean_noun = [\"kimchi\", \"bulgogi\", \"bibimbap\", \"japchae\"]\n",
    "adj.append(korean_adj)\n",
    "noun.append(korean_noun)\n",
    "# American\n",
    "american_adj = [\"juicy\", \"hearty\", \"classic\", \"smoky\"]\n",
    "american_noun = [\"burger\", \"ribs\", \"hot dog\", \"steak\"]\n",
    "adj.append(american_adj)\n",
    "noun.append(american_noun)\n",
    "# Cafeteria\n",
    "cafeteria_adj = [\"homemade\", \"wholesome\", \"nutritious\", \"hearty\"]\n",
    "cafeteria_noun = [\"meatloaf\", \"macaroni and cheese\", \"pot roast\", \"cornbread\"]\n",
    "adj.append(cafeteria_adj)\n",
    "noun.append(cafeteria_noun)\n",
    "# Juice\n",
    "juice_adj = [\"fresh\", \"cold-pressed\", \"nutritious\", \"invigorating\"]\n",
    "juice_noun = [\"smoothie\", \"juice\", \"detox\", \"cleanser\"]\n",
    "adj.append(juice_adj)\n",
    "noun.append(juice_noun)\n",
    "# Wine\n",
    "wine_adj = [\"full-bodied\", \"velvety\", \"oaky\", \"fruit-forward\"]\n",
    "wine_noun = [\"chardonnay\", \"merlot\", \"pinot noir\", \"cabernet sauvignon\"]\n",
    "adj.append(wine_adj)\n",
    "noun.append(wine_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de55595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "restaurant_names = []\n",
    "for i in range(len(adj)):\n",
    "    for j in range(30):\n",
    "        name = random.choice(adj[i]) + \" \" + random.choice(noun[i])\n",
    "        names.append(name)\n",
    "    unique_list = list(set(names))\n",
    "    restaurant_names.append(unique_list)\n",
    "    names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea1adc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flavorful salsa', 'tangy empanada', 'spicy taco', 'flavorful taco', 'zesty empanada', 'tangy taco', 'spicy chorizo', 'flavorful empanada', 'spicy salsa', 'flavorful chorizo', 'zesty chorizo', 'tangy chorizo', 'tangy salsa', 'zesty taco', 'spicy empanada', 'zesty salsa']\n"
     ]
    }
   ],
   "source": [
    "print(restaurant_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63028f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines = [\"Latin American\", \"Burgers\", \"African\", \"Turkish\", \"Bakery\", \"Sandwiches\", \"Italian\", \"Fast-Food\", \"Chinese\", \"Vegetarian\", \"Coffee\", \"Contemporary\", \"Dutch\", \"Ice-Cream\", \"Mexican\", \"Greek\", \"Japanese\", \"Pizzeria\", \"Steaks\", \"Asian\", \"Seafood\", \"Bar\", \"French\", \"International\", \"Bar Pub Brewery\", \"Korean\", \"American\", \"Cafeteria\", \"Juice\", \"Wine\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c5dd32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"restaurants.csv\", \"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(cuisines)\n",
    "    # Write each list to separate columns in the CSV file\n",
    "    i = 0\n",
    "    L = len(restaurant_names)\n",
    "    for row in zip(*restaurant_names):\n",
    "        writer.writerow(row)\n",
    "        i += 1\n",
    "        #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da2ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {key: [] for key in cuisines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1f8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Latin American': [], 'Burgers': [], 'African': [], 'Turkish': [], 'Bakery': [], 'Sandwiches': [], 'Italian': [], 'Fast-Food': [], 'Chinese': [], 'Vegetarian': [], 'Coffee': [], 'Contemporary': [], 'Dutch': [], 'Ice-Cream': [], 'Mexican': [], 'Greek': [], 'Japanese': [], 'Pizzeria': [], 'Steaks': [], 'Asian': [], 'Seafood': [], 'Bar': [], 'French': [], 'International': [], 'Bar Pub Brewery': [], 'Korean': [], 'American': [], 'Cafeteria': [], 'Juice': [], 'Wine': []}\n"
     ]
    }
   ],
   "source": [
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbba23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flavorful salsa', 'tangy empanada', 'spicy taco', 'flavorful taco', 'zesty empanada', 'tangy taco', 'spicy chorizo', 'flavorful empanada', 'spicy salsa', 'flavorful chorizo', 'zesty chorizo', 'tangy chorizo', 'tangy salsa', 'zesty taco', 'spicy empanada', 'zesty salsa']\n"
     ]
    }
   ],
   "source": [
    "print(restaurant_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e295db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cuisines)):\n",
    "    restaurant_names[i] = list(set(restaurant_names[i]))\n",
    "    my_dict[cuisines[i]].append(restaurant_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "136258f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['flavorful salsa', 'tangy empanada', 'spicy taco', 'flavorful taco', 'zesty empanada', 'zesty salsa', 'tangy taco', 'zesty chorizo', 'flavorful empanada', 'spicy salsa', 'flavorful chorizo', 'spicy empanada', 'tangy chorizo', 'zesty taco', 'spicy chorizo', 'tangy salsa']]\n"
     ]
    }
   ],
   "source": [
    "print(my_dict['Latin American'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dbc7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "with open('cuisine.csv', 'r', ) as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        csv_data.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "571d2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.array(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30270af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(csv_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9bd51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = csv_data.reshape(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434eea07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print(csv_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8229afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin American\n"
     ]
    }
   ],
   "source": [
    "print(csv_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee31533",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = np.delete(csv_data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30b236c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flavorful salsa',\n",
       "  'tangy empanada',\n",
       "  'spicy taco',\n",
       "  'flavorful taco',\n",
       "  'zesty empanada',\n",
       "  'zesty salsa',\n",
       "  'tangy taco',\n",
       "  'zesty chorizo',\n",
       "  'flavorful empanada',\n",
       "  'spicy salsa',\n",
       "  'flavorful chorizo',\n",
       "  'spicy empanada',\n",
       "  'tangy chorizo',\n",
       "  'zesty taco',\n",
       "  'spicy chorizo',\n",
       "  'tangy salsa']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict[csv_data[0]]\n",
    "#print(csv_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adcbacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = []\n",
    "for cus in csv_data:\n",
    "    \n",
    "    names = my_dict[cus]\n",
    "    #print(\"name\")\n",
    "    #print(names)\n",
    "    random_element = random.choice(names[0])\n",
    "    #print(\"rand\")\n",
    "    #print(random_element)\n",
    "    #break\n",
    "    names_list.append(random_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f98ddb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zesty chorizo', 'juicy cheese', 'fragrant stew', 'satisfying pide', 'sweet baguette', 'grilled panini', 'earthy fufu', 'authentic pizza', 'convenient burger', 'umami dumpling', 'smoky kebab', 'fresh salad', 'sizzling kebab', 'flavorful bao', 'fresh quinoa', 'rich latte', 'colorful bowl', 'creative fusion', 'wholesome kroket', 'decadent milkshake', 'spiced baklava', 'fresh pastry', 'satisfying poffertjes', 'colorful enchilada', 'fresh gyro', 'teriyaki izakaya', 'crispy pizza', 'juicy strip steak', 'gourmet focaccia', 'spicy stir-fry']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(names_list[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14884e20",
   "metadata": {},
   "outputs": [],
   "source": [
    " import csv\n",
    "\n",
    "with open('data.csv', mode='w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    i = 1 # Initialize the index counter\n",
    "    for item in names_list:\n",
    "        writer.writerow([i, item]) # Write the index and the item to the CSV file\n",
    "        i += 1 # Increment the index counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04d7c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('cap.csv', mode='w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    i = 1 # Initialize the index counter\n",
    "    for item in names_list:\n",
    "        # Capitalize the first character of each word in the item string\n",
    "        item = ' '.join([word.capitalize() for word in item.split()])\n",
    "        writer.writerow([i, item]) # Write the index and the item to the CSV file\n",
    "        i += 1 # Increment the index counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0c8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
